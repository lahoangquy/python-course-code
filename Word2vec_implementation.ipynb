{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKpnATPKnA5j",
        "outputId": "b6b488b9-459b-4e90-a23d-16555cbdadd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adjustText\n",
            "  Downloading adjustText-0.8-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from adjustText) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from adjustText) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->adjustText) (1.16.0)\n",
            "Installing collected packages: adjustText\n",
            "Successfully installed adjustText-0.8\n"
          ]
        }
      ],
      "source": [
        "pip install adjustText"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import zipfile\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "from sklearn.manifold import TSNE\n",
        "from adjustText import adjust_text"
      ],
      "metadata": {
        "id": "mYfXIUgrnGcF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWNL5RgfnYWN",
        "outputId": "2f4e32a7-dd1d-43cf-fa66-573a72561637"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw0j1X7jnZzN",
        "outputId": "e5d46592-7f30-47d6-a4e6-1bac865e849c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip'"
      ],
      "metadata": {
        "id": "ij29yeYMnb6Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project we will use BBC news articles dataset. It contains 2225 news articles belonging to 5 topics, business, entertainment, politics, sport, and tech which were published on the BBC website between 2004-2005"
      ],
      "metadata": {
        "id": "84sy2nXAptpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_data(url, data_dir):\n",
        "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
        "\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "    file_path = os.path.join(data_dir, 'bbc-fulltext.zip')\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        print('Downloading file...')\n",
        "        filename, _ = urlretrieve(url, file_path)\n",
        "    else:\n",
        "        print(\"File already exists\")\n",
        "\n",
        "    extract_path = os.path.join(data_dir, 'bbc')\n",
        "    if not os.path.exists(extract_path):\n",
        "\n",
        "        with zipfile.ZipFile(os.path.join(data_dir, 'bbc-fulltext.zip'), 'r') as zipf:\n",
        "            zipf.extractall(data_dir)\n",
        "\n",
        "    else:\n",
        "        print(\"bbc-fulltext.zip has already been extracted\")\n",
        "\n",
        "download_data(url, 'data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7bX7dhBp9rg",
        "outputId": "0c116e85-2c20-4bc1-801e-f25b82a676d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists\n",
            "bbc-fulltext.zip has already been extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function first creates data_dir if it does not exst. Next if the bbc-fulltext.zip file does not exist it will be downloaded from the URL. If bbc-fulltext.zip has not been extracted yet, it will be extracted to data_dir"
      ],
      "metadata": {
        "id": "_aszykr3rakW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With that we are going to focus on reading the data contained in the news articles (in .txt format) into the memory. To do that we will define the read_data() function which takes a data directory path (data_dir) and reads the .txt files (except for README file)"
      ],
      "metadata": {
        "id": "05NlTCM5rvVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(data_dir):\n",
        "\n",
        "    # This will contain the full list of stories\n",
        "    news_stories = []\n",
        "\n",
        "    print(\"Reading files\")\n",
        "\n",
        "    i = 0 # Just used for printing progress\n",
        "    for root, dirs, files in os.walk(data_dir):\n",
        "\n",
        "        for fi, f in enumerate(files):\n",
        "\n",
        "            # We don't read the readme file\n",
        "            if 'README' in f:\n",
        "                continue\n",
        "\n",
        "            # Printing progress\n",
        "            i += 1\n",
        "            print(\".\"*i, f, end='\\r')\n",
        "\n",
        "            # Open the file\n",
        "            with open(os.path.join(root, f), encoding='latin-1') as f:\n",
        "\n",
        "                story = []\n",
        "                # Read all the lines\n",
        "                for row in f:\n",
        "\n",
        "                    story.append(row.strip())\n",
        "\n",
        "                # Create a single string with all the rows in the doc\n",
        "                story = ' '.join(story)\n",
        "                # Add that to the list\n",
        "                news_stories.append(story)\n",
        "\n",
        "        print('', end='\\r')\n",
        "\n",
        "    print(f\"\\nDetected {len(news_stories)} stories\")\n",
        "    return news_stories"
      ],
      "metadata": {
        "id": "wYKxcyEhsFaD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with read_data() function. We can use it read the data and print some samples as well as some statistics"
      ],
      "metadata": {
        "id": "vO93yj7Bs-k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news_stories = read_data(os.path.join('data', 'bbc'))\n",
        "\n",
        "# Printing some stats and sample data\n",
        "print(f\"{sum([len(story.split(' ')) for story in news_stories])} words found in the total news set\")\n",
        "print('Example words (start): ',news_stories[0][:50])\n",
        "print('Example words (end): ',news_stories[-1][-50:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VNmIs5vtE2K",
        "outputId": "fc2d8427-c5ae-48c4-e15b-af22279c410b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading files\n",
            "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. 284.txt\n",
            "Detected 2225 stories\n",
            "865163 words found in the total news set\n",
            "Example words (start):  Musicians to tackle US red tape  Musicians' groups\n",
            "Example words (end):  illion songs downloaded since it launched in 2003.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be seen from the above result, there are 2225 stories with close to a milion words. In the next step we will tokenize each story (in the form of a long string) to a list of tokens (or words). Along with that we will perform some preprocessing on the text: lowercase all the chracfters and remove punctuation."
      ],
      "metadata": {
        "id": "x8mvPASdtnNc"
      }
    }
  ]
}