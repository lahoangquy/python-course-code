{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "There are 3 main types of categorires.\n",
        "\n",
        "1) Structured Data: This is the most organized form of data. It is represented in tabular formats such as Excel files and Comma-Separated Value (CSV) files.\n",
        "\n",
        "2) Semi-Structured Data: This type of data is not presented in a tabular structure, but it can be represented in a tabular format after transformation. Here, information is usually stored between tags following a definite pattern. XML and HTML files can be referred to as semi-structured data.\n",
        "\n",
        "3)Unstructured Data: This type of data is the most difficult to deal with. Machine learning algorithms would find it difficult to comprehend unstructured data without any loss of information. Text corpora and images are examples of unstructured data.\n",
        "\n",
        "Categorization of Data Based on Content:\n",
        "\n",
        "•\tText Data: This refers to text corpora consisting of written sentences. This type of data can only be read. An example would be the text corpus of a book.\n",
        "•\tImage Data: This refers to pictures that are used to communicate messages. This type of data can only be seen.\n",
        "•\tAudio Data: This refers to recordings of someone's voice, music, and so on. This type of data can only be heard.\n",
        "•\tVideo Data: A continuous series of images coupled with audio forms a video. This type of data can be seen as well as heard.\n",
        "\n"
      ],
      "metadata": {
        "id": "t4xawhC2O-Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "KyPy9wfBUpgq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oo25H8poOeB6"
      },
      "outputs": [],
      "source": [
        "sentence = 'Happy tweeted, \"Witnessing 90th Republic Day of Viet Nam from Jack, \\\n",
        "Ho CHi Minh. Mesmerizing performance by Vietnamese Army! Awesome airshow! @Viet_Nam_official \\\n",
        "@Viet_Nam_official #VietNam #90thRepublic_Day. For more photos ping me jack@photoking.com :)\"'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete all characters other than digits, alphabetical characters, and whitespaces from the text. Use the split() function to split the strings into parts."
      ],
      "metadata": {
        "id": "vbW5HSgZUx6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "re.sub(r'([^\\s\\w]|_)+', ' ', sentence).split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAW8LRjHUzRN",
        "outputId": "b0bb13b8-eb25-4662-c561-18913989d120"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Happy',\n",
              " 'tweeted',\n",
              " 'Witnessing',\n",
              " '90th',\n",
              " 'Republic',\n",
              " 'Day',\n",
              " 'of',\n",
              " 'Viet',\n",
              " 'Nam',\n",
              " 'from',\n",
              " 'Jack',\n",
              " 'Ho',\n",
              " 'CHi',\n",
              " 'Minh',\n",
              " 'Mesmerizing',\n",
              " 'performance',\n",
              " 'by',\n",
              " 'Vietnamese',\n",
              " 'Army',\n",
              " 'Awesome',\n",
              " 'airshow',\n",
              " 'Viet',\n",
              " 'Nam',\n",
              " 'official',\n",
              " 'Viet',\n",
              " 'Nam',\n",
              " 'official',\n",
              " 'VietNam',\n",
              " '90thRepublic',\n",
              " 'Day',\n",
              " 'For',\n",
              " 'more',\n",
              " 'photos',\n",
              " 'ping',\n",
              " 'me',\n",
              " 'jack',\n",
              " 'photoking',\n",
              " 'com']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually, extracting each token separately does not help. For instance, consider the sentence, \"I don't hate you, but your behavior.\" Here, if we process each of the tokens, such as \"hate\" and \"behavior,\" separately, then the true meaning of the sentence would not be comprehended. In this case, the context in which these tokens are present becomes essential. Thus, we consider n consecutive tokens at a time. n-grams refers to the grouping of n consecutive tokens together."
      ],
      "metadata": {
        "id": "whlPH1_MVXgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will extract n-grams by using nltk and textBlb"
      ],
      "metadata": {
        "id": "DMYViGL-Ve2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def n_gram_extractor(sentence, n):\n",
        "    tokens = re.sub(r'([^\\s\\w]|_)+', ' ', sentence).split()\n",
        "    for i in range(len(tokens)-n+1):\n",
        "        print(tokens[i:i+n])"
      ],
      "metadata": {
        "id": "YOu9TI1AVkXO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To check the bi-grams we need to pass the function with text and n\n",
        "n_gram_extractor('The cute little boy is playing with balls.', 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfbnqzHIWDtF",
        "outputId": "0f49b3e2-40b2-4ea0-aa9c-395e221ec514"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'cute']\n",
            "['cute', 'little']\n",
            "['little', 'boy']\n",
            "['boy', 'is']\n",
            "['is', 'playing']\n",
            "['playing', 'with']\n",
            "['with', 'balls']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To check the tri-grams we need to pass the function with text and n\n",
        "n_gram_extractor('The cute little boy is playing with balls.', 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGix-6fJWUUa",
        "outputId": "8b2236dd-233c-4ca7-f16a-2cbf3d63adcf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'cute', 'little']\n",
            "['cute', 'little', 'boy']\n",
            "['little', 'boy', 'is']\n",
            "['boy', 'is', 'playing']\n",
            "['is', 'playing', 'with']\n",
            "['playing', 'with', 'balls']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from textblob import TextBlob\n",
        "blob = TextBlob(\"The cute little boy is playing with balls.\")\n",
        "blob.ngrams(n=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJte-kLEWeil",
        "outputId": "fdac015f-5e96-41da-b622-9d8b926e775e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['The', 'cute']),\n",
              " WordList(['cute', 'little']),\n",
              " WordList(['little', 'boy']),\n",
              " WordList(['boy', 'is']),\n",
              " WordList(['is', 'playing']),\n",
              " WordList(['playing', 'with']),\n",
              " WordList(['with', 'balls'])]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from textblob import TextBlob\n",
        "blob = TextBlob(\"The cute little boy is playing with balls.\")\n",
        "blob.ngrams(n=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J2XVSiLW33L",
        "outputId": "0254e81a-014e-49fc-98db-e1178a347502"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['The', 'cute', 'little']),\n",
              " WordList(['cute', 'little', 'boy']),\n",
              " WordList(['little', 'boy', 'is']),\n",
              " WordList(['boy', 'is', 'playing']),\n",
              " WordList(['is', 'playing', 'with']),\n",
              " WordList(['playing', 'with', 'balls'])]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras and TextBlob are two of the most popular Python libraries used for performing various NLP tasks. TextBlob provides a simple and easy-to-use interface to do so. Keras is used mainly for performing deep learning-based NLP tasks"
      ],
      "metadata": {
        "id": "qSApLCg9XLc2"
      }
    }
  ]
}