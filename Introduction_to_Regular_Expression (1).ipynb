{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In natural langauge processing (NLP), regular expression (regex) are powerful and verstaile tools used to manipulate and analyze text data. A regular expression is a sequence of characters that defines a search pattern, allowing us to match and extract specific text patterns from unstructured text. Regular expressions provide a concise and expressive way to represent complex patterns making them essential for various text processing tasks.\n",
        "\n",
        "In NLP regular expressions are employed for the following taskS:\n",
        "\n",
        "\n",
        "\n",
        "*   Tokenization: Regular expressions are used to split text into individual tokens such as words, or phrases by defining specific patterns for delimiters\n",
        "\n",
        "*   Text cleaning and Preprocessing: Regular expressions help to remove unwanted characters , special symbols or puntuation from text resulting in clearner and more structured data\n",
        "\n",
        "*   Pattern Matching: Reuglar expressions enable the identification of specific patterns or sequences of characters within text, facilitating the extraction of valuable information\n",
        "\n",
        "*   Baned Entity Recognition (NER): Regular expressions are useful for identifying and extracting named entities like names of people, organization, locations and dates from text\n",
        "\n",
        "*   Text validation: Regular expressions can validate the format of user input such as email addresses, phone numbers or identifications numbers\n",
        "*   Text generation and replacement: Regualr expressions aloow for text generation or replacement, enabling the modification of specific patterns in the text.\n",
        "\n",
        "Regex patterns consist of a combination of ordinary characters and metacharacters that have special meanings. Metacharacters allow for flexible pttern matching repetion, grouping and more. For example, \".\" matches any character, '*' matches zero or more occurences and '[]' reoresebts a character class.\n",
        "\n",
        "\n",
        "While regular expressions offer powerful text processing capabilities, creating complex patterns can be challenging and might require careful consideration of text variations and edge cases. Therefore it is important to balance pattern expressiveness with readability and maintainability.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wi3Cj3hscNQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "s = \"A Rolex watch costs in the range of $3000.0 - $8000.0 in USA.\"\n",
        "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
        "tokenizer.tokenize(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FX7oWkm8lP4",
        "outputId": "311f4c4d-431d-4dc9-bbed-e4d3c24e997c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'Rolex',\n",
              " 'watch',\n",
              " 'costs',\n",
              " 'in',\n",
              " 'the',\n",
              " 'range',\n",
              " 'of',\n",
              " '$3000.0',\n",
              " '-',\n",
              " '$8000.0',\n",
              " 'in',\n",
              " 'USA',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \\w+|\\$[\\d\\.]+|\\S+ regular expression allows 3 alternative patterns:\n",
        "\n",
        "First alternative: \\w+ that matches any word character (equal to [a-zA-Z0-9]). The + is the quantifier and matches between 1 and unlimited times as many times as possible\n",
        "\n",
        "Second alternative is \\$[\\d\\.]+. Here \\$ matches the character $, \\d matches a digit between 0 and 9.  \\. matches the character . (period) and + again acts as a quantifier matching between 1 and unlimited times.\n",
        "\n",
        "Third alternative is \\S+. Here \\S accepts any non-whitesapce character and + again acts the same way as the above 2 alternative.\n",
        "\n",
        "\n",
        "There are other tokenizers built on top of the RegrexpTokenizer such as Blankline tokenizer which tokenizes a string treating blank lines as delimiters where blank lines are thse that contain no characters except spaces and tabs.\n",
        "\n",
        "The wordPunct tokenizer is another implementation on top of RegexpTokenizer, which tokenizes a text into a sequence of alphabetic and nonalphabetic characters using the regular expressioon \\w+|\\$[\\d\\.]+."
      ],
      "metadata": {
        "id": "vLpp4yPs9M24"
      }
    }
  ]
}