{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "GBM stands for Gradient Boosting Machine, which is a machine learning technique used for both regression and classification tasks. GBM builds a strong predictive model by sequentially combining multiple weak learners (typically decision trees) in an additive manner. Each new weak learner is trained to correct the errors of the previous learners, with the goal of minimizing a predefined loss function.\n",
        "\n",
        "The key idea behind GBM is to fit each weak learner to the residuals (the differences between the observed and predicted values) of the ensemble model constructed so far. This approach allows GBM to focus on the most challenging examples and gradually improve the overall predictive performance.\n",
        "\n",
        "GBM operates in a forward stage-wise manner, where each new weak learner is added to the ensemble to reduce the overall prediction error. The final prediction is made by summing the predictions of all weak learners, weighted by a learning rate parameter.\n",
        "\n",
        "XGBoost, short for Extreme Gradient Boosting, is an optimized implementation of gradient boosting that is known for its efficiency, scalability, and high performance. XGBoost extends traditional gradient boosting by introducing several enhancements and optimizations, including:\n",
        "\n",
        "Regularization: XGBoost incorporates L1 and L2 regularization techniques to prevent overfitting and improve generalization performance.\n",
        "\n",
        "Parallelization: XGBoost supports parallel and distributed computing, allowing it to scale efficiently to large datasets and multiple processors.\n",
        "\n",
        "Tree Pruning: XGBoost implements tree pruning algorithms to control the complexity of individual trees and reduce computational overhead.\n",
        "\n",
        "Customizable Loss Functions: XGBoost allows users to define and optimize custom loss functions, providing flexibility to handle different types of data and objectives.\n",
        "\n",
        "Missing Values Handling: XGBoost automatically handles missing values in the dataset, eliminating the need for manual preprocessing.\n",
        "\n",
        "XGBoost has become one of the most popular and widely used machine learning libraries due to its exceptional performance and versatility. It is commonly used in various applications, including classification, regression, ranking, and recommendation systems. Additionally, XGBoost has won numerous machine learning competitions and is considered a state-of-the-art algorithm in the field."
      ],
      "metadata": {
        "id": "R-SKTz03t7xf"
      }
    }
  ]
}